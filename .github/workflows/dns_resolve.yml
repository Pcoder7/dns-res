name: SanicDNS CI

on:
  workflow_dispatch:

permissions:
  contents: write
  
env:
  LINES_PER_CHUNK: 500000
  COMBINED_WORDLIST: "best-wordlist-9996122_filter.txt"

jobs:
  prepare_matrix:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GHCR_TOKEN }}
    outputs:
      matrix: ${{ steps.set_matrix.outputs.matrix }}
      unique_domains_json: ${{ steps.set_matrix.outputs.unique_domains_json }}
      all_chunk_basenames_json: ${{ steps.set_matrix.outputs.all_chunk_basenames_json }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          # Fetch full Git history so previous commits are available for comparison
          fetch-depth: 0   

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'

      - name: Cache Go modules & binaries
        uses: actions/cache@v3
        with:
          path: |
            $HOME/go/pkg/mod
            ~/.cache/go-build
            $HOME/go/bin
          key: ${{ runner.os }}-go-cache-${{ github.ref_name }}
          restore-keys: |
            ${{ runner.os }}-go-cache-
         

      - name: Cache Wordlists
        uses: actions/cache@v3
        with:
          path: |
            best-wordlist-9996122.txt
            seclistes-dns-7110368.txt
            resolvers.txt
            resolvers-trusted.txt
          key: wordlists-cache-v2-${{ hashFiles('best-wordlist-9996122.txt','seclistes-dns-7110368.txt','resolvers.txt','resolvers-trusted.txt') }}
          restore-keys: wordlists-cache-v2-

      - name: Fetch wordlists
        run: |
          # Download only if not cached already
          if [ ! -f best-wordlist-9996122.txt ]; then
            wget -qO best-wordlist-9996122.txt \
              https://github.com/Pcoder7/All-In-One-DNS-Wordlist/raw/refs/heads/main/best-wordlist-9996122.txt
          fi
          if [ ! -f seclistes-dns-7110368.txt ]; then
            wget -qO seclistes-dns-7110368.txt \
              https://github.com/Pcoder7/All-In-One-DNS-Wordlist/raw/refs/heads/main/seclistes-dns-7110368.txt
          fi
          if [ ! -f resolvers.txt ]; then
              wget -qO resolvers.txt \
              https://raw.githubusercontent.com/rix4uni/resolvers/refs/heads/main/resolvers.txt
              echo "resolvers.txt is downloaded"
          fi
          if [ ! -f resolvers-trusted.txt ]; then
              wget -qO resolvers-trusted.txt \
              https://raw.githubusercontent.com/and0x00/resolvers.txt/refs/heads/main/resolvers.txt
              echo "resolvers-trusted.txt is downloaded"
          fi          

      - name: Build filter_wordlist tool
        run: |
          go build -o filter_wordlist filter_wordlist.go
          chmod +x filter_wordlist

      - name: Cache filtered wordlists
        uses: actions/cache@v3
        with:
          path: |
            best-wordlist-9996122_filter.txt
            seclistes-dns-7110368_filter.txt
          key: filter-wordlists-${{ hashFiles('best-wordlist-9996122_filter.txt','seclistes-dns-7110368_filter.txt') }}
          restore-keys: filter-wordlists-

      - name: Filter and combine wordlists
        run: |
          if [ -f best-wordlist-9996122_filter.txt ]; then
            echo "Using cached filter."
          else
            ./filter_wordlist best-wordlist-9996122.txt > best-wordlist-9996122_filter.txt
            ./filter_wordlist seclistes-dns-7110368.txt > seclistes-dns-7110368_filter.txt
            cat seclistes-dns-7110368_filter.txt | anew -q best-wordlist-9996122_filter.txt > added-lines.txt
          fi

      - name: Split combined wordlist into chunks
        run: |
          mkdir -p chunks
          split -l $LINES_PER_CHUNK -a 2 --numeric-suffixes=1 "$COMBINED_WORDLIST" chunks/chunk_
          ls chunks | wc -l

      - name: Build matrix JSON and define outputs
        id: set_matrix
        run: |
          doms_jq=$(jq -R -s -c 'split("\n")|map(select(length>0))' domains.txt)
          chunks_jq=$(ls chunks | jq -R -s -c 'split("\n")|map(select(length>0))')
          full=$(jq -n --argjson D "$doms_jq" --argjson C "$chunks_jq" \
            '[ $D[] as $d | $C[] as $c | {domain:$d,chunk:"chunks/\($c)"} ]')
          echo "matrix<<EOF" >> $GITHUB_OUTPUT
          echo "$full" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          uniques=$(echo "$full" | jq 'map(.domain)|unique')
          echo "unique_domains_json<<EOF" >> $GITHUB_OUTPUT
          echo "$uniques" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "all_chunk_basenames_json<<EOF" >> $GITHUB_OUTPUT
          echo "$chunks_jq" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload chunks & resolvers
        uses: actions/upload-artifact@v4
        with:
          name: common-assets
          path: |
            chunks
            resolvers.txt
            resolvers-trusted.txt
            wildcards.txt
            massdns.txt
          retention-days: 1

  bruteforce:
    needs: prepare_matrix
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 20
      fail-fast: false
      matrix:
        pair: ${{ fromJson(needs.prepare_matrix.outputs.matrix) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Download common-assets
        uses: actions/download-artifact@v4
        with: 
           name: common-assets
      
      - name: Install system dependencies
        shell: bash
        run: |
          curl -sSL https://raw.githubusercontent.com/hadriansecurity/sanicdns/main/install.sh | sudo bash
     
      - name: Install ethtool & shrink NIC queues
        run: |
          sudo apt-get update
          sudo apt-get install -y ethtool
          # If eth0 doesn’t exist, adjust the interface name accordingly
          sudo ethtool -L eth0 combined 3 || true          

      - name: Allocate hugepages (1 GB)
        run: |
          # best-effort; if dpdk-hugepages.py isn't on PATH this will fail harmlessly
          sudo dpdk-hugepages.py --setup 2G || true

      - name: Verify installation
        run: |
          which sanicdns
          
      - name: Run SanicDNS against your lists
        run: |
          export TERM=xterm      
          DOMAIN="${{ matrix.pair.domain }}"
          CHUNK="${{ matrix.pair.chunk }}"
          OUTDIR="sanicdns_${DOMAIN//./_}_${CHUNK##*/}"
          mkdir -p "$OUTDIR"
          sudo sanicdns \
            -i "$CHUNK" \
            --postfix ".$DOMAIN" \
            -r 5000 \
            -c 20000 \
            --resolvers resolvers.txt \
            -o "$OUTDIR/out.txt" \
            -w 4 \
            --num-retries 10 \
            -t 7000
 

      - name: Upload SanicDNS results
        uses: actions/upload-artifact@v4
        with:
          name: sanicdns_${{ matrix.pair.domain }}_${{ matrix.pair.chunk }}
          path: |
            ${{ steps.run_sanicdns.outputs.OUTDIR }}/out.txt

  aggregate_results:
    needs: [prepare_matrix, bruteforce]
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/pcoder7/spider-puredns-actions:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GHCR_TOKEN }}
    strategy:
      fail-fast: false
      matrix:
        domain_from_prepare_matrix: ${{ fromJson(needs.prepare_matrix.outputs.unique_domains_json) }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Prepare directories and key vars
        id: prep_vars
        run: |
          DOMAIN="${{ matrix.domain_from_prepare_matrix }}"
          SAFE=$(echo "$DOMAIN" | tr '.' '_')
          OUT_REPO_DIR="results/$SAFE"
          TMP_DIR="temp_sanicdns/$SAFE"
          mkdir -p "$OUT_REPO_DIR" "$TMP_DIR"
          echo "DOMAIN=$DOMAIN"             >> $GITHUB_ENV
          echo "SAFE=$SAFE"                 >> $GITHUB_ENV
          echo "OUT_REPO_DIR=$OUT_REPO_DIR" >> $GITHUB_ENV
          echo "TMP_DIR=$TMP_DIR"           >> $GITHUB_ENV

      - name: Download all SanicDNS artifacts
        uses: actions/download-artifact@v4
        # no name → fetches all artifacts

      - name: Consolidate artifacts for ${{ env.DOMAIN }}
        run: |
          echo "Gathering artifacts for ${DOMAIN} (safe: ${SAFE})"
          for dir in sanicdns_${SAFE}_*; do
            [ -d "$dir" ] && cp -n "$dir"/out.txt "${TMP_DIR}/"
          done
          ls -lA "$TMP_DIR"

      - name: Aggregate SanicDNS results
        run: |
          mkdir -p "${OUT_REPO_DIR}"
          if compgen -G "${TMP_DIR}/out.txt" > /dev/null; then
            # Merge all out.txt files into one deduped list
            cat "${TMP_DIR}/out.txt" | sort -u > "${OUT_REPO_DIR}/sanicdns_results.txt"
          else
            echo "# No SanicDNS output for ${DOMAIN}" > "${OUT_REPO_DIR}/sanicdns_results.txt"
          fi

      - name: Upload aggregated results
        uses: actions/upload-artifact@v4
        with:
          name: sanicdns_results_${{ matrix.domain_from_prepare_matrix }}
          path: |
            ${{ env.OUT_REPO_DIR }}/sanicdns_results.txt
            
            
